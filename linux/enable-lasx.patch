diff --git a/arch/loongarch/Kconfig b/arch/loongarch/Kconfig
index c2ad57399dfe..e120701f9a10 100644
--- a/arch/loongarch/Kconfig
+++ b/arch/loongarch/Kconfig
@@ -263,10 +263,12 @@ config AS_HAS_EXPLICIT_RELOCS
 	def_bool $(as-instr,x:pcalau12i \$t0$(comma)%pc_hi20(x))
 
 config CC_HAS_LSX_VECTORS
-	def_bool $(cc-option,-mlsx)
+	bool
+	default y
 
 config CC_HAS_LASX_VECTORS
-	def_bool $(cc-option,-mlasx)
+	bool
+	default y
 
 config HARDWARE_WATCHPOINTS
 	bool
diff --git a/arch/loongarch/include/asm/asmmacro.h b/arch/loongarch/include/asm/asmmacro.h
index 3b41ec20b592..23907067fe2c 100644
--- a/arch/loongarch/include/asm/asmmacro.h
+++ b/arch/loongarch/include/asm/asmmacro.h
@@ -581,77 +581,81 @@
 	.endm
 
 	.macro	lsx_save_data thread tmp
-	li.w	\tmp, THREAD_FPR0
-	PTR_ADD \tmp, \thread, \tmp
-	vst	$vr0, \tmp, THREAD_FPR0  - THREAD_FPR0
-	vst	$vr1, \tmp, THREAD_FPR1  - THREAD_FPR0
-	vst	$vr2, \tmp, THREAD_FPR2  - THREAD_FPR0
-	vst	$vr3, \tmp, THREAD_FPR3  - THREAD_FPR0
-	vst	$vr4, \tmp, THREAD_FPR4  - THREAD_FPR0
-	vst	$vr5, \tmp, THREAD_FPR5  - THREAD_FPR0
-	vst	$vr6, \tmp, THREAD_FPR6  - THREAD_FPR0
-	vst	$vr7, \tmp, THREAD_FPR7  - THREAD_FPR0
-	vst	$vr8, \tmp, THREAD_FPR8  - THREAD_FPR0
-	vst	$vr9, \tmp, THREAD_FPR9  - THREAD_FPR0
-	vst	$vr10, \tmp, THREAD_FPR10 - THREAD_FPR0
-	vst	$vr11, \tmp, THREAD_FPR11 - THREAD_FPR0
-	vst	$vr12, \tmp, THREAD_FPR12 - THREAD_FPR0
-	vst	$vr13, \tmp, THREAD_FPR13 - THREAD_FPR0
-	vst	$vr14, \tmp, THREAD_FPR14 - THREAD_FPR0
-	vst	$vr15, \tmp, THREAD_FPR15 - THREAD_FPR0
-	vst	$vr16, \tmp, THREAD_FPR16 - THREAD_FPR0
-	vst	$vr17, \tmp, THREAD_FPR17 - THREAD_FPR0
-	vst	$vr18, \tmp, THREAD_FPR18 - THREAD_FPR0
-	vst	$vr19, \tmp, THREAD_FPR19 - THREAD_FPR0
-	vst	$vr20, \tmp, THREAD_FPR20 - THREAD_FPR0
-	vst	$vr21, \tmp, THREAD_FPR21 - THREAD_FPR0
-	vst	$vr22, \tmp, THREAD_FPR22 - THREAD_FPR0
-	vst	$vr23, \tmp, THREAD_FPR23 - THREAD_FPR0
-	vst	$vr24, \tmp, THREAD_FPR24 - THREAD_FPR0
-	vst	$vr25, \tmp, THREAD_FPR25 - THREAD_FPR0
-	vst	$vr26, \tmp, THREAD_FPR26 - THREAD_FPR0
-	vst	$vr27, \tmp, THREAD_FPR27 - THREAD_FPR0
-	vst	$vr28, \tmp, THREAD_FPR28 - THREAD_FPR0
-	vst	$vr29, \tmp, THREAD_FPR29 - THREAD_FPR0
-	vst	$vr30, \tmp, THREAD_FPR30 - THREAD_FPR0
-	vst	$vr31, \tmp, THREAD_FPR31 - THREAD_FPR0
+	parse_r __tmp, \tmp
+	li.w		\tmp, THREAD_FPR0
+	PTR_ADD 	\tmp, \thread, \tmp
+	/* vst opcode is 0xb1 */
+	.word (0xb1 << 22 | ((THREAD_FPR0-THREAD_FPR0) << 10) | __tmp << 5 | 0)
+	.word (0xb1 << 22 | ((THREAD_FPR1-THREAD_FPR0) << 10) | __tmp << 5 | 1)
+	.word (0xb1 << 22 | ((THREAD_FPR2-THREAD_FPR0) << 10) | __tmp << 5 | 2)
+	.word (0xb1 << 22 | ((THREAD_FPR3-THREAD_FPR0) << 10) | __tmp << 5 | 3)
+	.word (0xb1 << 22 | ((THREAD_FPR4-THREAD_FPR0) << 10) | __tmp << 5 | 4)
+	.word (0xb1 << 22 | ((THREAD_FPR5-THREAD_FPR0) << 10) | __tmp << 5 | 5)
+	.word (0xb1 << 22 | ((THREAD_FPR6-THREAD_FPR0) << 10) | __tmp << 5 | 6)
+	.word (0xb1 << 22 | ((THREAD_FPR7-THREAD_FPR0) << 10) | __tmp << 5 | 7)
+	.word (0xb1 << 22 | ((THREAD_FPR8-THREAD_FPR0) << 10) | __tmp << 5 | 8)
+	.word (0xb1 << 22 | ((THREAD_FPR9-THREAD_FPR0) << 10) | __tmp << 5 | 9)
+	.word (0xb1 << 22 | ((THREAD_FPR10-THREAD_FPR0) << 10) | __tmp << 5 | 10)
+	.word (0xb1 << 22 | ((THREAD_FPR11-THREAD_FPR0) << 10) | __tmp << 5 | 11)
+	.word (0xb1 << 22 | ((THREAD_FPR12-THREAD_FPR0) << 10) | __tmp << 5 | 12)
+	.word (0xb1 << 22 | ((THREAD_FPR13-THREAD_FPR0) << 10) | __tmp << 5 | 13)
+	.word (0xb1 << 22 | ((THREAD_FPR14-THREAD_FPR0) << 10) | __tmp << 5 | 14)
+	.word (0xb1 << 22 | ((THREAD_FPR15-THREAD_FPR0) << 10) | __tmp << 5 | 15)
+	.word (0xb1 << 22 | ((THREAD_FPR16-THREAD_FPR0) << 10) | __tmp << 5 | 16)
+	.word (0xb1 << 22 | ((THREAD_FPR17-THREAD_FPR0) << 10) | __tmp << 5 | 17)
+	.word (0xb1 << 22 | ((THREAD_FPR18-THREAD_FPR0) << 10) | __tmp << 5 | 18)
+	.word (0xb1 << 22 | ((THREAD_FPR19-THREAD_FPR0) << 10) | __tmp << 5 | 19)
+	.word (0xb1 << 22 | ((THREAD_FPR20-THREAD_FPR0) << 10) | __tmp << 5 | 20)
+	.word (0xb1 << 22 | ((THREAD_FPR21-THREAD_FPR0) << 10) | __tmp << 5 | 21)
+	.word (0xb1 << 22 | ((THREAD_FPR22-THREAD_FPR0) << 10) | __tmp << 5 | 22)
+	.word (0xb1 << 22 | ((THREAD_FPR23-THREAD_FPR0) << 10) | __tmp << 5 | 23)
+	.word (0xb1 << 22 | ((THREAD_FPR24-THREAD_FPR0) << 10) | __tmp << 5 | 24)
+	.word (0xb1 << 22 | ((THREAD_FPR25-THREAD_FPR0) << 10) | __tmp << 5 | 25)
+	.word (0xb1 << 22 | ((THREAD_FPR26-THREAD_FPR0) << 10) | __tmp << 5 | 26)
+	.word (0xb1 << 22 | ((THREAD_FPR27-THREAD_FPR0) << 10) | __tmp << 5 | 27)
+	.word (0xb1 << 22 | ((THREAD_FPR28-THREAD_FPR0) << 10) | __tmp << 5 | 28)
+	.word (0xb1 << 22 | ((THREAD_FPR29-THREAD_FPR0) << 10) | __tmp << 5 | 29)
+	.word (0xb1 << 22 | ((THREAD_FPR30-THREAD_FPR0) << 10) | __tmp << 5 | 30)
+	.word (0xb1 << 22 | ((THREAD_FPR31-THREAD_FPR0) << 10) | __tmp << 5 | 31)
 	.endm
 
 	.macro	lsx_restore_data thread tmp
-	li.w	\tmp, THREAD_FPR0
-	PTR_ADD	\tmp, \thread, \tmp
-	vld	$vr0, \tmp, THREAD_FPR0  - THREAD_FPR0
-	vld	$vr1, \tmp, THREAD_FPR1  - THREAD_FPR0
-	vld	$vr2, \tmp, THREAD_FPR2  - THREAD_FPR0
-	vld	$vr3, \tmp, THREAD_FPR3  - THREAD_FPR0
-	vld	$vr4, \tmp, THREAD_FPR4  - THREAD_FPR0
-	vld	$vr5, \tmp, THREAD_FPR5  - THREAD_FPR0
-	vld	$vr6, \tmp, THREAD_FPR6  - THREAD_FPR0
-	vld	$vr7, \tmp, THREAD_FPR7  - THREAD_FPR0
-	vld	$vr8, \tmp, THREAD_FPR8  - THREAD_FPR0
-	vld	$vr9, \tmp, THREAD_FPR9  - THREAD_FPR0
-	vld	$vr10, \tmp, THREAD_FPR10 - THREAD_FPR0
-	vld	$vr11, \tmp, THREAD_FPR11 - THREAD_FPR0
-	vld	$vr12, \tmp, THREAD_FPR12 - THREAD_FPR0
-	vld	$vr13, \tmp, THREAD_FPR13 - THREAD_FPR0
-	vld	$vr14, \tmp, THREAD_FPR14 - THREAD_FPR0
-	vld	$vr15, \tmp, THREAD_FPR15 - THREAD_FPR0
-	vld	$vr16, \tmp, THREAD_FPR16 - THREAD_FPR0
-	vld	$vr17, \tmp, THREAD_FPR17 - THREAD_FPR0
-	vld	$vr18, \tmp, THREAD_FPR18 - THREAD_FPR0
-	vld	$vr19, \tmp, THREAD_FPR19 - THREAD_FPR0
-	vld	$vr20, \tmp, THREAD_FPR20 - THREAD_FPR0
-	vld	$vr21, \tmp, THREAD_FPR21 - THREAD_FPR0
-	vld	$vr22, \tmp, THREAD_FPR22 - THREAD_FPR0
-	vld	$vr23, \tmp, THREAD_FPR23 - THREAD_FPR0
-	vld	$vr24, \tmp, THREAD_FPR24 - THREAD_FPR0
-	vld	$vr25, \tmp, THREAD_FPR25 - THREAD_FPR0
-	vld	$vr26, \tmp, THREAD_FPR26 - THREAD_FPR0
-	vld	$vr27, \tmp, THREAD_FPR27 - THREAD_FPR0
-	vld	$vr28, \tmp, THREAD_FPR28 - THREAD_FPR0
-	vld	$vr29, \tmp, THREAD_FPR29 - THREAD_FPR0
-	vld	$vr30, \tmp, THREAD_FPR30 - THREAD_FPR0
-	vld	$vr31, \tmp, THREAD_FPR31 - THREAD_FPR0
+	parse_r __tmp, \tmp
+	li.w		\tmp, THREAD_FPR0
+	PTR_ADD		\tmp, \thread, \tmp
+	/* vld opcode is 0xb0 */
+	.word (0xb0 << 22 | ((THREAD_FPR0-THREAD_FPR0) << 10) | __tmp << 5 | 0)
+	.word (0xb0 << 22 | ((THREAD_FPR1-THREAD_FPR0) << 10) | __tmp << 5 | 1)
+	.word (0xb0 << 22 | ((THREAD_FPR2-THREAD_FPR0) << 10) | __tmp << 5 | 2)
+	.word (0xb0 << 22 | ((THREAD_FPR3-THREAD_FPR0) << 10) | __tmp << 5 | 3)
+	.word (0xb0 << 22 | ((THREAD_FPR4-THREAD_FPR0) << 10) | __tmp << 5 | 4)
+	.word (0xb0 << 22 | ((THREAD_FPR5-THREAD_FPR0) << 10) | __tmp << 5 | 5)
+	.word (0xb0 << 22 | ((THREAD_FPR6-THREAD_FPR0) << 10) | __tmp << 5 | 6)
+	.word (0xb0 << 22 | ((THREAD_FPR7-THREAD_FPR0) << 10) | __tmp << 5 | 7)
+	.word (0xb0 << 22 | ((THREAD_FPR8-THREAD_FPR0) << 10) | __tmp << 5 | 8)
+	.word (0xb0 << 22 | ((THREAD_FPR9-THREAD_FPR0) << 10) | __tmp << 5 | 9)
+	.word (0xb0 << 22 | ((THREAD_FPR10-THREAD_FPR0) << 10) | __tmp << 5 | 10)
+	.word (0xb0 << 22 | ((THREAD_FPR11-THREAD_FPR0) << 10) | __tmp << 5 | 11)
+	.word (0xb0 << 22 | ((THREAD_FPR12-THREAD_FPR0) << 10) | __tmp << 5 | 12)
+	.word (0xb0 << 22 | ((THREAD_FPR13-THREAD_FPR0) << 10) | __tmp << 5 | 13)
+	.word (0xb0 << 22 | ((THREAD_FPR14-THREAD_FPR0) << 10) | __tmp << 5 | 14)
+	.word (0xb0 << 22 | ((THREAD_FPR15-THREAD_FPR0) << 10) | __tmp << 5 | 15)
+	.word (0xb0 << 22 | ((THREAD_FPR16-THREAD_FPR0) << 10) | __tmp << 5 | 16)
+	.word (0xb0 << 22 | ((THREAD_FPR17-THREAD_FPR0) << 10) | __tmp << 5 | 17)
+	.word (0xb0 << 22 | ((THREAD_FPR18-THREAD_FPR0) << 10) | __tmp << 5 | 18)
+	.word (0xb0 << 22 | ((THREAD_FPR19-THREAD_FPR0) << 10) | __tmp << 5 | 19)
+	.word (0xb0 << 22 | ((THREAD_FPR20-THREAD_FPR0) << 10) | __tmp << 5 | 20)
+	.word (0xb0 << 22 | ((THREAD_FPR21-THREAD_FPR0) << 10) | __tmp << 5 | 21)
+	.word (0xb0 << 22 | ((THREAD_FPR22-THREAD_FPR0) << 10) | __tmp << 5 | 22)
+	.word (0xb0 << 22 | ((THREAD_FPR23-THREAD_FPR0) << 10) | __tmp << 5 | 23)
+	.word (0xb0 << 22 | ((THREAD_FPR24-THREAD_FPR0) << 10) | __tmp << 5 | 24)
+	.word (0xb0 << 22 | ((THREAD_FPR25-THREAD_FPR0) << 10) | __tmp << 5 | 25)
+	.word (0xb0 << 22 | ((THREAD_FPR26-THREAD_FPR0) << 10) | __tmp << 5 | 26)
+	.word (0xb0 << 22 | ((THREAD_FPR27-THREAD_FPR0) << 10) | __tmp << 5 | 27)
+	.word (0xb0 << 22 | ((THREAD_FPR28-THREAD_FPR0) << 10) | __tmp << 5 | 28)
+	.word (0xb0 << 22 | ((THREAD_FPR29-THREAD_FPR0) << 10) | __tmp << 5 | 29)
+	.word (0xb0 << 22 | ((THREAD_FPR30-THREAD_FPR0) << 10) | __tmp << 5 | 30)
+	.word (0xb0 << 22 | ((THREAD_FPR31-THREAD_FPR0) << 10) | __tmp << 5 | 31)
 	.endm
 
 	.macro	lsx_save_all	thread tmp0 tmp1
@@ -667,8 +671,11 @@
 	.endm
 
 	.macro	lsx_save_upper vd base tmp off
-	vpickve2gr.d	\tmp, \vd, 1
-	st.d		\tmp, \base, (\off+8)
+	parse_vr __vd, \vd
+	parse_r __tmp, \tmp
+	/* vpickve2gr opcode is 0xe5dfe */
+	.word (0xe5dfe << 11 | 1 << 10 | __vd << 5 | __tmp)
+	st.d	\tmp, \base, (\off+8)
 	.endm
 
 	.macro	lsx_save_all_upper thread base tmp
@@ -709,8 +716,11 @@
 	.endm
 
 	.macro	lsx_restore_upper vd base tmp off
-	ld.d		\tmp, \base, (\off+8)
-	vinsgr2vr.d	\vd,  \tmp, 1
+	parse_vr __vd, \vd
+	parse_r __tmp, \tmp
+	ld.d	\tmp, \base, (\off+8)
+	/* vinsgr2vr opcode is 0xe5d7e */
+	.word	(0xe5d7e << 11 | 1 << 10 | __tmp << 5 | __vd)
 	.endm
 
 	.macro	lsx_restore_all_upper thread base tmp
@@ -751,7 +761,10 @@
 	.endm
 
 	.macro	lsx_init_upper vd tmp
-	vinsgr2vr.d	\vd, \tmp, 1
+	parse_vr __vd, \vd
+	parse_r __tmp, \tmp
+	/* vinsgr2vr opcode is 0xe5d7e */
+	.word	(0xe5d7e << 11 | 1 << 10 | __tmp << 5 | __vd)
 	.endm
 
 	.macro	lsx_init_all_upper tmp
@@ -791,77 +804,81 @@
 	.endm
 
 	.macro	lasx_save_data thread tmp
-	li.w	\tmp, THREAD_FPR0
-	PTR_ADD	\tmp, \thread, \tmp
-	xvst	$xr0, \tmp, THREAD_FPR0  - THREAD_FPR0
-	xvst	$xr1, \tmp, THREAD_FPR1  - THREAD_FPR0
-	xvst	$xr2, \tmp, THREAD_FPR2  - THREAD_FPR0
-	xvst	$xr3, \tmp, THREAD_FPR3  - THREAD_FPR0
-	xvst	$xr4, \tmp, THREAD_FPR4  - THREAD_FPR0
-	xvst	$xr5, \tmp, THREAD_FPR5  - THREAD_FPR0
-	xvst	$xr6, \tmp, THREAD_FPR6  - THREAD_FPR0
-	xvst	$xr7, \tmp, THREAD_FPR7  - THREAD_FPR0
-	xvst	$xr8, \tmp, THREAD_FPR8  - THREAD_FPR0
-	xvst	$xr9, \tmp, THREAD_FPR9  - THREAD_FPR0
-	xvst	$xr10, \tmp, THREAD_FPR10 - THREAD_FPR0
-	xvst	$xr11, \tmp, THREAD_FPR11 - THREAD_FPR0
-	xvst	$xr12, \tmp, THREAD_FPR12 - THREAD_FPR0
-	xvst	$xr13, \tmp, THREAD_FPR13 - THREAD_FPR0
-	xvst	$xr14, \tmp, THREAD_FPR14 - THREAD_FPR0
-	xvst	$xr15, \tmp, THREAD_FPR15 - THREAD_FPR0
-	xvst	$xr16, \tmp, THREAD_FPR16 - THREAD_FPR0
-	xvst	$xr17, \tmp, THREAD_FPR17 - THREAD_FPR0
-	xvst	$xr18, \tmp, THREAD_FPR18 - THREAD_FPR0
-	xvst	$xr19, \tmp, THREAD_FPR19 - THREAD_FPR0
-	xvst	$xr20, \tmp, THREAD_FPR20 - THREAD_FPR0
-	xvst	$xr21, \tmp, THREAD_FPR21 - THREAD_FPR0
-	xvst	$xr22, \tmp, THREAD_FPR22 - THREAD_FPR0
-	xvst	$xr23, \tmp, THREAD_FPR23 - THREAD_FPR0
-	xvst	$xr24, \tmp, THREAD_FPR24 - THREAD_FPR0
-	xvst	$xr25, \tmp, THREAD_FPR25 - THREAD_FPR0
-	xvst	$xr26, \tmp, THREAD_FPR26 - THREAD_FPR0
-	xvst	$xr27, \tmp, THREAD_FPR27 - THREAD_FPR0
-	xvst	$xr28, \tmp, THREAD_FPR28 - THREAD_FPR0
-	xvst	$xr29, \tmp, THREAD_FPR29 - THREAD_FPR0
-	xvst	$xr30, \tmp, THREAD_FPR30 - THREAD_FPR0
-	xvst	$xr31, \tmp, THREAD_FPR31 - THREAD_FPR0
+	parse_r __tmp, \tmp
+	li.w            \tmp, THREAD_FPR0
+	PTR_ADD         \tmp, \thread, \tmp
+	/* xvst opcode is 0xb3 */
+	.word (0xb3 << 22 | ((THREAD_FPR0-THREAD_FPR0) << 10) | __tmp << 5 | 0)
+	.word (0xb3 << 22 | ((THREAD_FPR1-THREAD_FPR0) << 10) | __tmp << 5 | 1)
+	.word (0xb3 << 22 | ((THREAD_FPR2-THREAD_FPR0) << 10) | __tmp << 5 | 2)
+	.word (0xb3 << 22 | ((THREAD_FPR3-THREAD_FPR0) << 10) | __tmp << 5 | 3)
+	.word (0xb3 << 22 | ((THREAD_FPR4-THREAD_FPR0) << 10) | __tmp << 5 | 4)
+	.word (0xb3 << 22 | ((THREAD_FPR5-THREAD_FPR0) << 10) | __tmp << 5 | 5)
+	.word (0xb3 << 22 | ((THREAD_FPR6-THREAD_FPR0) << 10) | __tmp << 5 | 6)
+	.word (0xb3 << 22 | ((THREAD_FPR7-THREAD_FPR0) << 10) | __tmp << 5 | 7)
+	.word (0xb3 << 22 | ((THREAD_FPR8-THREAD_FPR0) << 10) | __tmp << 5 | 8)
+	.word (0xb3 << 22 | ((THREAD_FPR9-THREAD_FPR0) << 10) | __tmp << 5 | 9)
+	.word (0xb3 << 22 | ((THREAD_FPR10-THREAD_FPR0) << 10) | __tmp << 5 | 10)
+	.word (0xb3 << 22 | ((THREAD_FPR11-THREAD_FPR0) << 10) | __tmp << 5 | 11)
+	.word (0xb3 << 22 | ((THREAD_FPR12-THREAD_FPR0) << 10) | __tmp << 5 | 12)
+	.word (0xb3 << 22 | ((THREAD_FPR13-THREAD_FPR0) << 10) | __tmp << 5 | 13)
+	.word (0xb3 << 22 | ((THREAD_FPR14-THREAD_FPR0) << 10) | __tmp << 5 | 14)
+	.word (0xb3 << 22 | ((THREAD_FPR15-THREAD_FPR0) << 10) | __tmp << 5 | 15)
+	.word (0xb3 << 22 | ((THREAD_FPR16-THREAD_FPR0) << 10) | __tmp << 5 | 16)
+	.word (0xb3 << 22 | ((THREAD_FPR17-THREAD_FPR0) << 10) | __tmp << 5 | 17)
+	.word (0xb3 << 22 | ((THREAD_FPR18-THREAD_FPR0) << 10) | __tmp << 5 | 18)
+	.word (0xb3 << 22 | ((THREAD_FPR19-THREAD_FPR0) << 10) | __tmp << 5 | 19)
+	.word (0xb3 << 22 | ((THREAD_FPR20-THREAD_FPR0) << 10) | __tmp << 5 | 20)
+	.word (0xb3 << 22 | ((THREAD_FPR21-THREAD_FPR0) << 10) | __tmp << 5 | 21)
+	.word (0xb3 << 22 | ((THREAD_FPR22-THREAD_FPR0) << 10) | __tmp << 5 | 22)
+	.word (0xb3 << 22 | ((THREAD_FPR23-THREAD_FPR0) << 10) | __tmp << 5 | 23)
+	.word (0xb3 << 22 | ((THREAD_FPR24-THREAD_FPR0) << 10) | __tmp << 5 | 24)
+	.word (0xb3 << 22 | ((THREAD_FPR25-THREAD_FPR0) << 10) | __tmp << 5 | 25)
+	.word (0xb3 << 22 | ((THREAD_FPR26-THREAD_FPR0) << 10) | __tmp << 5 | 26)
+	.word (0xb3 << 22 | ((THREAD_FPR27-THREAD_FPR0) << 10) | __tmp << 5 | 27)
+	.word (0xb3 << 22 | ((THREAD_FPR28-THREAD_FPR0) << 10) | __tmp << 5 | 28)
+	.word (0xb3 << 22 | ((THREAD_FPR29-THREAD_FPR0) << 10) | __tmp << 5 | 29)
+	.word (0xb3 << 22 | ((THREAD_FPR30-THREAD_FPR0) << 10) | __tmp << 5 | 30)
+	.word (0xb3 << 22 | ((THREAD_FPR31-THREAD_FPR0) << 10) | __tmp << 5 | 31)
 	.endm
 
 	.macro	lasx_restore_data thread tmp
-	li.w	\tmp, THREAD_FPR0
-	PTR_ADD	\tmp, \thread, \tmp
-	xvld	$xr0, \tmp, THREAD_FPR0  - THREAD_FPR0
-	xvld	$xr1, \tmp, THREAD_FPR1  - THREAD_FPR0
-	xvld	$xr2, \tmp, THREAD_FPR2  - THREAD_FPR0
-	xvld	$xr3, \tmp, THREAD_FPR3  - THREAD_FPR0
-	xvld	$xr4, \tmp, THREAD_FPR4  - THREAD_FPR0
-	xvld	$xr5, \tmp, THREAD_FPR5  - THREAD_FPR0
-	xvld	$xr6, \tmp, THREAD_FPR6  - THREAD_FPR0
-	xvld	$xr7, \tmp, THREAD_FPR7  - THREAD_FPR0
-	xvld	$xr8, \tmp, THREAD_FPR8  - THREAD_FPR0
-	xvld	$xr9, \tmp, THREAD_FPR9  - THREAD_FPR0
-	xvld	$xr10, \tmp, THREAD_FPR10 - THREAD_FPR0
-	xvld	$xr11, \tmp, THREAD_FPR11 - THREAD_FPR0
-	xvld	$xr12, \tmp, THREAD_FPR12 - THREAD_FPR0
-	xvld	$xr13, \tmp, THREAD_FPR13 - THREAD_FPR0
-	xvld	$xr14, \tmp, THREAD_FPR14 - THREAD_FPR0
-	xvld	$xr15, \tmp, THREAD_FPR15 - THREAD_FPR0
-	xvld	$xr16, \tmp, THREAD_FPR16 - THREAD_FPR0
-	xvld	$xr17, \tmp, THREAD_FPR17 - THREAD_FPR0
-	xvld	$xr18, \tmp, THREAD_FPR18 - THREAD_FPR0
-	xvld	$xr19, \tmp, THREAD_FPR19 - THREAD_FPR0
-	xvld	$xr20, \tmp, THREAD_FPR20 - THREAD_FPR0
-	xvld	$xr21, \tmp, THREAD_FPR21 - THREAD_FPR0
-	xvld	$xr22, \tmp, THREAD_FPR22 - THREAD_FPR0
-	xvld	$xr23, \tmp, THREAD_FPR23 - THREAD_FPR0
-	xvld	$xr24, \tmp, THREAD_FPR24 - THREAD_FPR0
-	xvld	$xr25, \tmp, THREAD_FPR25 - THREAD_FPR0
-	xvld	$xr26, \tmp, THREAD_FPR26 - THREAD_FPR0
-	xvld	$xr27, \tmp, THREAD_FPR27 - THREAD_FPR0
-	xvld	$xr28, \tmp, THREAD_FPR28 - THREAD_FPR0
-	xvld	$xr29, \tmp, THREAD_FPR29 - THREAD_FPR0
-	xvld	$xr30, \tmp, THREAD_FPR30 - THREAD_FPR0
-	xvld	$xr31, \tmp, THREAD_FPR31 - THREAD_FPR0
+	parse_r __tmp, \tmp
+	li.w            \tmp, THREAD_FPR0
+	PTR_ADD         \tmp, \thread, \tmp
+	/* xvld opcode is 0xb2 */
+	.word (0xb2 << 22 | ((THREAD_FPR0-THREAD_FPR0) << 10) | __tmp << 5 | 0)
+	.word (0xb2 << 22 | ((THREAD_FPR1-THREAD_FPR0) << 10) | __tmp << 5 | 1)
+	.word (0xb2 << 22 | ((THREAD_FPR2-THREAD_FPR0) << 10) | __tmp << 5 | 2)
+	.word (0xb2 << 22 | ((THREAD_FPR3-THREAD_FPR0) << 10) | __tmp << 5 | 3)
+	.word (0xb2 << 22 | ((THREAD_FPR4-THREAD_FPR0) << 10) | __tmp << 5 | 4)
+	.word (0xb2 << 22 | ((THREAD_FPR5-THREAD_FPR0) << 10) | __tmp << 5 | 5)
+	.word (0xb2 << 22 | ((THREAD_FPR6-THREAD_FPR0) << 10) | __tmp << 5 | 6)
+	.word (0xb2 << 22 | ((THREAD_FPR7-THREAD_FPR0) << 10) | __tmp << 5 | 7)
+	.word (0xb2 << 22 | ((THREAD_FPR8-THREAD_FPR0) << 10) | __tmp << 5 | 8)
+	.word (0xb2 << 22 | ((THREAD_FPR9-THREAD_FPR0) << 10) | __tmp << 5 | 9)
+	.word (0xb2 << 22 | ((THREAD_FPR10-THREAD_FPR0) << 10) | __tmp << 5 | 10)
+	.word (0xb2 << 22 | ((THREAD_FPR11-THREAD_FPR0) << 10) | __tmp << 5 | 11)
+	.word (0xb2 << 22 | ((THREAD_FPR12-THREAD_FPR0) << 10) | __tmp << 5 | 12)
+	.word (0xb2 << 22 | ((THREAD_FPR13-THREAD_FPR0) << 10) | __tmp << 5 | 13)
+	.word (0xb2 << 22 | ((THREAD_FPR14-THREAD_FPR0) << 10) | __tmp << 5 | 14)
+	.word (0xb2 << 22 | ((THREAD_FPR15-THREAD_FPR0) << 10) | __tmp << 5 | 15)
+	.word (0xb2 << 22 | ((THREAD_FPR16-THREAD_FPR0) << 10) | __tmp << 5 | 16)
+	.word (0xb2 << 22 | ((THREAD_FPR17-THREAD_FPR0) << 10) | __tmp << 5 | 17)
+	.word (0xb2 << 22 | ((THREAD_FPR18-THREAD_FPR0) << 10) | __tmp << 5 | 18)
+	.word (0xb2 << 22 | ((THREAD_FPR19-THREAD_FPR0) << 10) | __tmp << 5 | 19)
+	.word (0xb2 << 22 | ((THREAD_FPR20-THREAD_FPR0) << 10) | __tmp << 5 | 20)
+	.word (0xb2 << 22 | ((THREAD_FPR21-THREAD_FPR0) << 10) | __tmp << 5 | 21)
+	.word (0xb2 << 22 | ((THREAD_FPR22-THREAD_FPR0) << 10) | __tmp << 5 | 22)
+	.word (0xb2 << 22 | ((THREAD_FPR23-THREAD_FPR0) << 10) | __tmp << 5 | 23)
+	.word (0xb2 << 22 | ((THREAD_FPR24-THREAD_FPR0) << 10) | __tmp << 5 | 24)
+	.word (0xb2 << 22 | ((THREAD_FPR25-THREAD_FPR0) << 10) | __tmp << 5 | 25)
+	.word (0xb2 << 22 | ((THREAD_FPR26-THREAD_FPR0) << 10) | __tmp << 5 | 26)
+	.word (0xb2 << 22 | ((THREAD_FPR27-THREAD_FPR0) << 10) | __tmp << 5 | 27)
+	.word (0xb2 << 22 | ((THREAD_FPR28-THREAD_FPR0) << 10) | __tmp << 5 | 28)
+	.word (0xb2 << 22 | ((THREAD_FPR29-THREAD_FPR0) << 10) | __tmp << 5 | 29)
+	.word (0xb2 << 22 | ((THREAD_FPR30-THREAD_FPR0) << 10) | __tmp << 5 | 30)
+	.word (0xb2 << 22 | ((THREAD_FPR31-THREAD_FPR0) << 10) | __tmp << 5 | 31)
 	.endm
 
 	.macro	lasx_save_all	thread tmp0 tmp1
@@ -884,57 +901,65 @@
 	/* Nothing */
 	.endm
 
-	.macro	lasx_restore_upper xd base tmp0 tmp1 off
-	vld		\tmp0, \base, (\off+16)
-	xvpermi.q 	\xd,   \tmp1, 0x2
+	.macro lasx_restore_upper xd base tmp off
+	parse_xr __xd, \xd
+	parse_xr __xt, \tmp
+	parse_r __base, \base
+	/* vld opcode is 0xb0 */
+	.word (0xb0 << 22 | (\off+16) << 10 | __base << 5 | __xt)
+	/* xvpermi.q opcode is 0x1dfb */
+	.word (0x1dfb << 18 | 0x2 << 10 | __xt << 5 | __xd)
 	.endm
 
 	.macro	lasx_restore_all_upper thread base tmp
-	li.w		\tmp, THREAD_FPR0
-	PTR_ADD		\base, \thread, \tmp
-	/* Save $vr31 ($xr31 lower bits) with xvpickve2gr */
-	xvpickve2gr.d	$r17, $xr31, 0
-	xvpickve2gr.d	$r18, $xr31, 1
-	lasx_restore_upper $xr0, \base, $vr31, $xr31, (THREAD_FPR0-THREAD_FPR0)
-	lasx_restore_upper $xr1, \base, $vr31, $xr31, (THREAD_FPR1-THREAD_FPR0)
-	lasx_restore_upper $xr2, \base, $vr31, $xr31, (THREAD_FPR2-THREAD_FPR0)
-	lasx_restore_upper $xr3, \base, $vr31, $xr31, (THREAD_FPR3-THREAD_FPR0)
-	lasx_restore_upper $xr4, \base, $vr31, $xr31, (THREAD_FPR4-THREAD_FPR0)
-	lasx_restore_upper $xr5, \base, $vr31, $xr31, (THREAD_FPR5-THREAD_FPR0)
-	lasx_restore_upper $xr6, \base, $vr31, $xr31, (THREAD_FPR6-THREAD_FPR0)
-	lasx_restore_upper $xr7, \base, $vr31, $xr31, (THREAD_FPR7-THREAD_FPR0)
-	lasx_restore_upper $xr8, \base, $vr31, $xr31, (THREAD_FPR8-THREAD_FPR0)
-	lasx_restore_upper $xr9, \base, $vr31, $xr31, (THREAD_FPR9-THREAD_FPR0)
-	lasx_restore_upper $xr10, \base, $vr31, $xr31, (THREAD_FPR10-THREAD_FPR0)
-	lasx_restore_upper $xr11, \base, $vr31, $xr31, (THREAD_FPR11-THREAD_FPR0)
-	lasx_restore_upper $xr12, \base, $vr31, $xr31, (THREAD_FPR12-THREAD_FPR0)
-	lasx_restore_upper $xr13, \base, $vr31, $xr31, (THREAD_FPR13-THREAD_FPR0)
-	lasx_restore_upper $xr14, \base, $vr31, $xr31, (THREAD_FPR14-THREAD_FPR0)
-	lasx_restore_upper $xr15, \base, $vr31, $xr31, (THREAD_FPR15-THREAD_FPR0)
-	lasx_restore_upper $xr16, \base, $vr31, $xr31, (THREAD_FPR16-THREAD_FPR0)
-	lasx_restore_upper $xr17, \base, $vr31, $xr31, (THREAD_FPR17-THREAD_FPR0)
-	lasx_restore_upper $xr18, \base, $vr31, $xr31, (THREAD_FPR18-THREAD_FPR0)
-	lasx_restore_upper $xr19, \base, $vr31, $xr31, (THREAD_FPR19-THREAD_FPR0)
-	lasx_restore_upper $xr20, \base, $vr31, $xr31, (THREAD_FPR20-THREAD_FPR0)
-	lasx_restore_upper $xr21, \base, $vr31, $xr31, (THREAD_FPR21-THREAD_FPR0)
-	lasx_restore_upper $xr22, \base, $vr31, $xr31, (THREAD_FPR22-THREAD_FPR0)
-	lasx_restore_upper $xr23, \base, $vr31, $xr31, (THREAD_FPR23-THREAD_FPR0)
-	lasx_restore_upper $xr24, \base, $vr31, $xr31, (THREAD_FPR24-THREAD_FPR0)
-	lasx_restore_upper $xr25, \base, $vr31, $xr31, (THREAD_FPR25-THREAD_FPR0)
-	lasx_restore_upper $xr26, \base, $vr31, $xr31, (THREAD_FPR26-THREAD_FPR0)
-	lasx_restore_upper $xr27, \base, $vr31, $xr31, (THREAD_FPR27-THREAD_FPR0)
-	lasx_restore_upper $xr28, \base, $vr31, $xr31, (THREAD_FPR28-THREAD_FPR0)
-	lasx_restore_upper $xr29, \base, $vr31, $xr31, (THREAD_FPR29-THREAD_FPR0)
-	lasx_restore_upper $xr30, \base, $vr31, $xr31, (THREAD_FPR30-THREAD_FPR0)
-	lasx_restore_upper $xr31, \base, $vr31, $xr31, (THREAD_FPR31-THREAD_FPR0)
-	/* Restore $vr31 ($xr31 lower bits) with xvinsgr2vr */
-	xvinsgr2vr.d	$xr31, $r17, 0
-	xvinsgr2vr.d	$xr31, $r18, 1
+	li.w	\tmp, THREAD_FPR0
+	PTR_ADD	\base, \thread, \tmp
+	/* Save $vr31, xvpickve2gr opcode is 0x76efe */
+	.word (0x76efe << 12 | 0 << 10 | 31 << 5 | 0x11)
+	.word (0x76efe << 12 | 1 << 10 | 31 << 5 | 0x12)
+	lasx_restore_upper $xr0, \base, $xr31, (THREAD_FPR0-THREAD_FPR0)
+	lasx_restore_upper $xr1, \base, $xr31, (THREAD_FPR1-THREAD_FPR0)
+	lasx_restore_upper $xr2, \base, $xr31, (THREAD_FPR2-THREAD_FPR0)
+	lasx_restore_upper $xr3, \base, $xr31, (THREAD_FPR3-THREAD_FPR0)
+	lasx_restore_upper $xr4, \base, $xr31, (THREAD_FPR4-THREAD_FPR0)
+	lasx_restore_upper $xr5, \base, $xr31, (THREAD_FPR5-THREAD_FPR0)
+	lasx_restore_upper $xr6, \base, $xr31, (THREAD_FPR6-THREAD_FPR0)
+	lasx_restore_upper $xr7, \base, $xr31, (THREAD_FPR7-THREAD_FPR0)
+	lasx_restore_upper $xr8, \base, $xr31, (THREAD_FPR8-THREAD_FPR0)
+	lasx_restore_upper $xr9, \base, $xr31, (THREAD_FPR9-THREAD_FPR0)
+	lasx_restore_upper $xr10, \base, $xr31, (THREAD_FPR10-THREAD_FPR0)
+	lasx_restore_upper $xr11, \base, $xr31, (THREAD_FPR11-THREAD_FPR0)
+	lasx_restore_upper $xr12, \base, $xr31, (THREAD_FPR12-THREAD_FPR0)
+	lasx_restore_upper $xr13, \base, $xr31, (THREAD_FPR13-THREAD_FPR0)
+	lasx_restore_upper $xr14, \base, $xr31, (THREAD_FPR14-THREAD_FPR0)
+	lasx_restore_upper $xr15, \base, $xr31, (THREAD_FPR15-THREAD_FPR0)
+	lasx_restore_upper $xr16, \base, $xr31, (THREAD_FPR16-THREAD_FPR0)
+	lasx_restore_upper $xr17, \base, $xr31, (THREAD_FPR17-THREAD_FPR0)
+	lasx_restore_upper $xr18, \base, $xr31, (THREAD_FPR18-THREAD_FPR0)
+	lasx_restore_upper $xr19, \base, $xr31, (THREAD_FPR19-THREAD_FPR0)
+	lasx_restore_upper $xr20, \base, $xr31, (THREAD_FPR20-THREAD_FPR0)
+	lasx_restore_upper $xr21, \base, $xr31, (THREAD_FPR21-THREAD_FPR0)
+	lasx_restore_upper $xr22, \base, $xr31, (THREAD_FPR22-THREAD_FPR0)
+	lasx_restore_upper $xr23, \base, $xr31, (THREAD_FPR23-THREAD_FPR0)
+	lasx_restore_upper $xr24, \base, $xr31, (THREAD_FPR24-THREAD_FPR0)
+	lasx_restore_upper $xr25, \base, $xr31, (THREAD_FPR25-THREAD_FPR0)
+	lasx_restore_upper $xr26, \base, $xr31, (THREAD_FPR26-THREAD_FPR0)
+	lasx_restore_upper $xr27, \base, $xr31, (THREAD_FPR27-THREAD_FPR0)
+	lasx_restore_upper $xr28, \base, $xr31, (THREAD_FPR28-THREAD_FPR0)
+	lasx_restore_upper $xr29, \base, $xr31, (THREAD_FPR29-THREAD_FPR0)
+	lasx_restore_upper $xr30, \base, $xr31, (THREAD_FPR30-THREAD_FPR0)
+	lasx_restore_upper $xr31, \base, $xr31, (THREAD_FPR31-THREAD_FPR0)
+	/* Restore $vr31, xvinsgr2vr opcode is 0x76ebe */
+	.word (0x76ebe << 12 | 0 << 10 | 0x11 << 5 | 31)
+	.word (0x76ebe << 12 | 1 << 10 | 0x12 << 5 | 31)
 	.endm
 
 	.macro	lasx_init_upper xd tmp
-	xvinsgr2vr.d	\xd, \tmp, 2
-	xvinsgr2vr.d	\xd, \tmp, 3
+	parse_xr __xd, \xd
+	parse_r __tmp, \tmp
+	/* xvinsgr2vr opcode is 0x76ebe */
+	.word	(0x76ebe << 12 | 2 << 10 | __tmp << 5 | __xd)
+	.word	(0x76ebe << 12 | 3 << 10 | __tmp << 5 | __xd)
 	.endm
 
 	.macro	lasx_init_all_upper tmp
diff --git a/arch/loongarch/kernel/fpu.S b/arch/loongarch/kernel/fpu.S
index 9526b15f1c83..653716e405b2 100644
--- a/arch/loongarch/kernel/fpu.S
+++ b/arch/loongarch/kernel/fpu.S
@@ -25,6 +25,26 @@
 	_asm_extable .ex\@, fault
 	.endm
 
+	.macro	EX_V insn, reg, src, offs
+	parse_v __insn, \insn
+	parse_v __offs, \offs
+	parse_r __src, \src
+	parse_vr __reg, \reg
+.ex\@:
+	.word __insn << 22 | __offs << 10 | __src << 5 | __reg
+	_asm_extable .ex\@, fault
+	.endm
+
+	.macro	EX_XV insn, reg, src, offs
+	parse_v __insn, \insn
+	parse_v __offs, \offs
+	parse_r __src, \src
+	parse_xr __reg, \reg
+.ex\@:
+	.word __insn << 22 | __offs << 10 | __src << 5 | __reg
+	_asm_extable .ex\@, fault
+	.endm
+
 	.macro sc_save_fp base
 	EX	fst.d	$f0,  \base, (0 * FPU_REG_WIDTH)
 	EX	fst.d	$f1,  \base, (1 * FPU_REG_WIDTH)
@@ -154,149 +174,149 @@
 
 	.macro sc_save_lsx base
 #ifdef CONFIG_CPU_HAS_LSX
-	EX	vst	$vr0,  \base, (0 * LSX_REG_WIDTH)
-	EX	vst	$vr1,  \base, (1 * LSX_REG_WIDTH)
-	EX	vst	$vr2,  \base, (2 * LSX_REG_WIDTH)
-	EX	vst	$vr3,  \base, (3 * LSX_REG_WIDTH)
-	EX	vst	$vr4,  \base, (4 * LSX_REG_WIDTH)
-	EX	vst	$vr5,  \base, (5 * LSX_REG_WIDTH)
-	EX	vst	$vr6,  \base, (6 * LSX_REG_WIDTH)
-	EX	vst	$vr7,  \base, (7 * LSX_REG_WIDTH)
-	EX	vst	$vr8,  \base, (8 * LSX_REG_WIDTH)
-	EX	vst	$vr9,  \base, (9 * LSX_REG_WIDTH)
-	EX	vst	$vr10, \base, (10 * LSX_REG_WIDTH)
-	EX	vst	$vr11, \base, (11 * LSX_REG_WIDTH)
-	EX	vst	$vr12, \base, (12 * LSX_REG_WIDTH)
-	EX	vst	$vr13, \base, (13 * LSX_REG_WIDTH)
-	EX	vst	$vr14, \base, (14 * LSX_REG_WIDTH)
-	EX	vst	$vr15, \base, (15 * LSX_REG_WIDTH)
-	EX	vst	$vr16, \base, (16 * LSX_REG_WIDTH)
-	EX	vst	$vr17, \base, (17 * LSX_REG_WIDTH)
-	EX	vst	$vr18, \base, (18 * LSX_REG_WIDTH)
-	EX	vst	$vr19, \base, (19 * LSX_REG_WIDTH)
-	EX	vst	$vr20, \base, (20 * LSX_REG_WIDTH)
-	EX	vst	$vr21, \base, (21 * LSX_REG_WIDTH)
-	EX	vst	$vr22, \base, (22 * LSX_REG_WIDTH)
-	EX	vst	$vr23, \base, (23 * LSX_REG_WIDTH)
-	EX	vst	$vr24, \base, (24 * LSX_REG_WIDTH)
-	EX	vst	$vr25, \base, (25 * LSX_REG_WIDTH)
-	EX	vst	$vr26, \base, (26 * LSX_REG_WIDTH)
-	EX	vst	$vr27, \base, (27 * LSX_REG_WIDTH)
-	EX	vst	$vr28, \base, (28 * LSX_REG_WIDTH)
-	EX	vst	$vr29, \base, (29 * LSX_REG_WIDTH)
-	EX	vst	$vr30, \base, (30 * LSX_REG_WIDTH)
-	EX	vst	$vr31, \base, (31 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr0,  \base,	(0 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr1,  \base,	(1 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr2,  \base,	(2 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr3,  \base,	(3 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr4,  \base,	(4 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr5,  \base,	(5 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr6,  \base,	(6 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr7,  \base,	(7 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr8,  \base,	(8 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr9,  \base,	(9 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr10,  \base, (10 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr11,  \base, (11 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr12,  \base, (12 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr13,  \base, (13 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr14,  \base, (14 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr15,  \base, (15 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr16,  \base, (16 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr17,  \base, (17 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr18,  \base, (18 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr19,  \base, (19 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr20,  \base, (20 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr21,  \base, (21 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr22,  \base, (22 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr23,  \base, (23 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr24,  \base, (24 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr25,  \base, (25 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr26,  \base, (26 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr27,  \base, (27 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr28,  \base, (28 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr29,  \base, (29 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr30,  \base, (30 * LSX_REG_WIDTH)
+	EX_V 0xb1 $vr31,  \base, (31 * LSX_REG_WIDTH)
 #endif
 	.endm
 
 	.macro sc_restore_lsx base
 #ifdef CONFIG_CPU_HAS_LSX
-	EX	vld	$vr0,  \base, (0 * LSX_REG_WIDTH)
-	EX	vld	$vr1,  \base, (1 * LSX_REG_WIDTH)
-	EX	vld	$vr2,  \base, (2 * LSX_REG_WIDTH)
-	EX	vld	$vr3,  \base, (3 * LSX_REG_WIDTH)
-	EX	vld	$vr4,  \base, (4 * LSX_REG_WIDTH)
-	EX	vld	$vr5,  \base, (5 * LSX_REG_WIDTH)
-	EX	vld	$vr6,  \base, (6 * LSX_REG_WIDTH)
-	EX	vld	$vr7,  \base, (7 * LSX_REG_WIDTH)
-	EX	vld	$vr8,  \base, (8 * LSX_REG_WIDTH)
-	EX	vld	$vr9,  \base, (9 * LSX_REG_WIDTH)
-	EX	vld	$vr10, \base, (10 * LSX_REG_WIDTH)
-	EX	vld	$vr11, \base, (11 * LSX_REG_WIDTH)
-	EX	vld	$vr12, \base, (12 * LSX_REG_WIDTH)
-	EX	vld	$vr13, \base, (13 * LSX_REG_WIDTH)
-	EX	vld	$vr14, \base, (14 * LSX_REG_WIDTH)
-	EX	vld	$vr15, \base, (15 * LSX_REG_WIDTH)
-	EX	vld	$vr16, \base, (16 * LSX_REG_WIDTH)
-	EX	vld	$vr17, \base, (17 * LSX_REG_WIDTH)
-	EX	vld	$vr18, \base, (18 * LSX_REG_WIDTH)
-	EX	vld	$vr19, \base, (19 * LSX_REG_WIDTH)
-	EX	vld	$vr20, \base, (20 * LSX_REG_WIDTH)
-	EX	vld	$vr21, \base, (21 * LSX_REG_WIDTH)
-	EX	vld	$vr22, \base, (22 * LSX_REG_WIDTH)
-	EX	vld	$vr23, \base, (23 * LSX_REG_WIDTH)
-	EX	vld	$vr24, \base, (24 * LSX_REG_WIDTH)
-	EX	vld	$vr25, \base, (25 * LSX_REG_WIDTH)
-	EX	vld	$vr26, \base, (26 * LSX_REG_WIDTH)
-	EX	vld	$vr27, \base, (27 * LSX_REG_WIDTH)
-	EX	vld	$vr28, \base, (28 * LSX_REG_WIDTH)
-	EX	vld	$vr29, \base, (29 * LSX_REG_WIDTH)
-	EX	vld	$vr30, \base, (30 * LSX_REG_WIDTH)
-	EX	vld	$vr31, \base, (31 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr0,  \base, (0 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr1,  \base, (1 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr2,  \base, (2 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr3,  \base, (3 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr4,  \base, (4 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr5,  \base, (5 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr6,  \base, (6 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr7,  \base, (7 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr8,  \base, (8 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr9,  \base, (9 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr10,  \base, (10 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr11,  \base, (11 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr12,  \base, (12 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr13,  \base, (13 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr14,  \base, (14 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr15,  \base, (15 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr16,  \base, (16 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr17,  \base, (17 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr18,  \base, (18 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr19,  \base, (19 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr20,  \base, (20 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr21,  \base, (21 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr22,  \base, (22 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr23,  \base, (23 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr24,  \base, (24 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr25,  \base, (25 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr26,  \base, (26 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr27,  \base, (27 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr28,  \base, (28 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr29,  \base, (29 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr30,  \base, (30 * LSX_REG_WIDTH)
+	EX_V 0xb0 $vr31,  \base, (31 * LSX_REG_WIDTH)
 #endif
 	.endm
 
 	.macro sc_save_lasx base
 #ifdef CONFIG_CPU_HAS_LASX
-	EX	xvst	$xr0,  \base, (0 * LASX_REG_WIDTH)
-	EX	xvst	$xr1,  \base, (1 * LASX_REG_WIDTH)
-	EX	xvst	$xr2,  \base, (2 * LASX_REG_WIDTH)
-	EX	xvst	$xr3,  \base, (3 * LASX_REG_WIDTH)
-	EX	xvst	$xr4,  \base, (4 * LASX_REG_WIDTH)
-	EX	xvst	$xr5,  \base, (5 * LASX_REG_WIDTH)
-	EX	xvst	$xr6,  \base, (6 * LASX_REG_WIDTH)
-	EX	xvst	$xr7,  \base, (7 * LASX_REG_WIDTH)
-	EX	xvst	$xr8,  \base, (8 * LASX_REG_WIDTH)
-	EX	xvst	$xr9,  \base, (9 * LASX_REG_WIDTH)
-	EX	xvst	$xr10, \base, (10 * LASX_REG_WIDTH)
-	EX	xvst	$xr11, \base, (11 * LASX_REG_WIDTH)
-	EX	xvst	$xr12, \base, (12 * LASX_REG_WIDTH)
-	EX	xvst	$xr13, \base, (13 * LASX_REG_WIDTH)
-	EX	xvst	$xr14, \base, (14 * LASX_REG_WIDTH)
-	EX	xvst	$xr15, \base, (15 * LASX_REG_WIDTH)
-	EX	xvst	$xr16, \base, (16 * LASX_REG_WIDTH)
-	EX	xvst	$xr17, \base, (17 * LASX_REG_WIDTH)
-	EX	xvst	$xr18, \base, (18 * LASX_REG_WIDTH)
-	EX	xvst	$xr19, \base, (19 * LASX_REG_WIDTH)
-	EX	xvst	$xr20, \base, (20 * LASX_REG_WIDTH)
-	EX	xvst	$xr21, \base, (21 * LASX_REG_WIDTH)
-	EX	xvst	$xr22, \base, (22 * LASX_REG_WIDTH)
-	EX	xvst	$xr23, \base, (23 * LASX_REG_WIDTH)
-	EX	xvst	$xr24, \base, (24 * LASX_REG_WIDTH)
-	EX	xvst	$xr25, \base, (25 * LASX_REG_WIDTH)
-	EX	xvst	$xr26, \base, (26 * LASX_REG_WIDTH)
-	EX	xvst	$xr27, \base, (27 * LASX_REG_WIDTH)
-	EX	xvst	$xr28, \base, (28 * LASX_REG_WIDTH)
-	EX	xvst	$xr29, \base, (29 * LASX_REG_WIDTH)
-	EX	xvst	$xr30, \base, (30 * LASX_REG_WIDTH)
-	EX	xvst	$xr31, \base, (31 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr0,  \base, (0 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr1,  \base, (1 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr2,  \base, (2 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr3,  \base, (3 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr4,  \base, (4 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr5,  \base, (5 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr6,  \base, (6 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr7,  \base, (7 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr8,  \base, (8 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr9,  \base, (9 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr10, \base, (10 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr11, \base, (11 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr12, \base, (12 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr13, \base, (13 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr14, \base, (14 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr15, \base, (15 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr16, \base, (16 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr17, \base, (17 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr18, \base, (18 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr19, \base, (19 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr20, \base, (20 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr21, \base, (21 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr22, \base, (22 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr23, \base, (23 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr24, \base, (24 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr25, \base, (25 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr26, \base, (26 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr27, \base, (27 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr28, \base, (28 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr29, \base, (29 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr30, \base, (30 * LASX_REG_WIDTH)
+	EX_XV	0xb3 $xr31, \base, (31 * LASX_REG_WIDTH)
 #endif
 	.endm
 
 	.macro sc_restore_lasx base
 #ifdef CONFIG_CPU_HAS_LASX
-	EX	xvld	$xr0,  \base, (0 * LASX_REG_WIDTH)
-	EX	xvld	$xr1,  \base, (1 * LASX_REG_WIDTH)
-	EX	xvld	$xr2,  \base, (2 * LASX_REG_WIDTH)
-	EX	xvld	$xr3,  \base, (3 * LASX_REG_WIDTH)
-	EX	xvld	$xr4,  \base, (4 * LASX_REG_WIDTH)
-	EX	xvld	$xr5,  \base, (5 * LASX_REG_WIDTH)
-	EX	xvld	$xr6,  \base, (6 * LASX_REG_WIDTH)
-	EX	xvld	$xr7,  \base, (7 * LASX_REG_WIDTH)
-	EX	xvld	$xr8,  \base, (8 * LASX_REG_WIDTH)
-	EX	xvld	$xr9,  \base, (9 * LASX_REG_WIDTH)
-	EX	xvld	$xr10, \base, (10 * LASX_REG_WIDTH)
-	EX	xvld	$xr11, \base, (11 * LASX_REG_WIDTH)
-	EX	xvld	$xr12, \base, (12 * LASX_REG_WIDTH)
-	EX	xvld	$xr13, \base, (13 * LASX_REG_WIDTH)
-	EX	xvld	$xr14, \base, (14 * LASX_REG_WIDTH)
-	EX	xvld	$xr15, \base, (15 * LASX_REG_WIDTH)
-	EX	xvld	$xr16, \base, (16 * LASX_REG_WIDTH)
-	EX	xvld	$xr17, \base, (17 * LASX_REG_WIDTH)
-	EX	xvld	$xr18, \base, (18 * LASX_REG_WIDTH)
-	EX	xvld	$xr19, \base, (19 * LASX_REG_WIDTH)
-	EX	xvld	$xr20, \base, (20 * LASX_REG_WIDTH)
-	EX	xvld	$xr21, \base, (21 * LASX_REG_WIDTH)
-	EX	xvld	$xr22, \base, (22 * LASX_REG_WIDTH)
-	EX	xvld	$xr23, \base, (23 * LASX_REG_WIDTH)
-	EX	xvld	$xr24, \base, (24 * LASX_REG_WIDTH)
-	EX	xvld	$xr25, \base, (25 * LASX_REG_WIDTH)
-	EX	xvld	$xr26, \base, (26 * LASX_REG_WIDTH)
-	EX	xvld	$xr27, \base, (27 * LASX_REG_WIDTH)
-	EX	xvld	$xr28, \base, (28 * LASX_REG_WIDTH)
-	EX	xvld	$xr29, \base, (29 * LASX_REG_WIDTH)
-	EX	xvld	$xr30, \base, (30 * LASX_REG_WIDTH)
-	EX	xvld	$xr31, \base, (31 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr0,  \base, (0 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr1,  \base, (1 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr2,  \base, (2 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr3,  \base, (3 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr4,  \base, (4 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr5,  \base, (5 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr6,  \base, (6 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr7,  \base, (7 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr8,  \base, (8 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr9,  \base, (9 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr10, \base, (10 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr11, \base, (11 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr12, \base, (12 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr13, \base, (13 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr14, \base, (14 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr15, \base, (15 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr16, \base, (16 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr17, \base, (17 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr18, \base, (18 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr19, \base, (19 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr20, \base, (20 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr21, \base, (21 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr22, \base, (22 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr23, \base, (23 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr24, \base, (24 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr25, \base, (25 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr26, \base, (26 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr27, \base, (27 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr28, \base, (28 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr29, \base, (29 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr30, \base, (30 * LASX_REG_WIDTH)
+	EX_XV	0xb2 $xr31, \base, (31 * LASX_REG_WIDTH)
 #endif
 	.endm
 
